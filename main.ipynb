{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries and setting up dir locations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "data_loc = \"data\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the Datasets\n",
    "\n",
    "train_data_raw = pd.read_csv(data_loc + \"train.csv\")\n",
    "test_data = pd.read_csv(data_loc + \"test.csv\")\n",
    "misconcept = pd.read_csv(data_loc + \"misconception_mapping.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating ID Text Mappings for later use\n",
    "\n",
    "construct_map = train_data_raw[['ConstructId','ConstructName']].drop_duplicates()\n",
    "subject_map = train_data_raw[['SubjectId','SubjectName']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_merge\n",
      "both          4370\n",
      "left_only        0\n",
      "right_only       0\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Dropping the unecessary text fields which have been mapped\n",
    "train_data = train_data_raw.drop(['ConstructName','SubjectName'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "### Melting the dataframe to map each option with their Option ID\n",
    "train_data = train_data.melt(id_vars = ['SubjectId','ConstructId','QuestionId','QuestionText','CorrectAnswer'],\n",
    "                             var_name=\"Column Name\", value_name=\"Value\")\n",
    "# using regex to get the Option ID A B C D\n",
    "train_data['Option'] = train_data['Column Name'].apply(lambda x: re.sub(\"[^A-Z]\",\"\",x)[1])\n",
    "# Using the Option ID to get the type of Column -> Answer Text or Misconception ID\n",
    "train_data['Column Type'] = train_data.apply(lambda x: x['Column Name'][0] + x['Column Name'][1:].split(x['Option'])[0] + \"Id\", axis=1)\n",
    "train_data = train_data.drop('Column Name', axis=1)\n",
    "\n",
    "\n",
    "### Removing Lines where the answer is correct\n",
    "train_data = train_data[train_data.apply(lambda x: x['CorrectAnswer']!=x['Option'], axis=1)]\n",
    "# Pivoting back with 2 columns -> Answer Text and the Misonception\n",
    "train_data = train_data.pivot(index = ['SubjectId','ConstructId','QuestionId','QuestionText','CorrectAnswer','Option'],\n",
    "                 columns = 'Column Type', values= 'Value').reset_index()\n",
    "# Removing Lines which dont have any misconception\n",
    "no_misconcept = train_data[train_data['MisconceptionId'].isnull()!=False]\n",
    "train_data = train_data[train_data['MisconceptionId'].isnull()==False]\n",
    "\n",
    "\n",
    "\n",
    "### Getting the Misconception Text based on ID for my review\n",
    "train_data['MisconceptionId'] = train_data['MisconceptionId'].astype(int)\n",
    "misconcept['MisconceptionId'] = misconcept['MisconceptionId'].astype(int)\n",
    "train_data = train_data.merge(misconcept.drop_duplicates(subset = 'MisconceptionId'), \n",
    "                              on = 'MisconceptionId', how = 'left', indicator = True)\n",
    "print(train_data._merge.value_counts())\n",
    "train_data = train_data.drop(\"_merge\", axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MisconceptionId\n",
       "3     10\n",
       "8      9\n",
       "9      9\n",
       "2      8\n",
       "5      8\n",
       "11     8\n",
       "12     8\n",
       "14     8\n",
       "1      7\n",
       "7      7\n",
       "17     6\n",
       "4      6\n",
       "10     6\n",
       "15     6\n",
       "19     5\n",
       "28     4\n",
       "22     4\n",
       "21     4\n",
       "20     4\n",
       "6      4\n",
       "18     4\n",
       "13     4\n",
       "16     3\n",
       "35     2\n",
       "34     2\n",
       "32     2\n",
       "23     2\n",
       "25     2\n",
       "24     2\n",
       "29     1\n",
       "30     1\n",
       "26     1\n",
       "47     1\n",
       "36     1\n",
       "37     1\n",
       "42     1\n",
       "45     1\n",
       "49     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.groupby(\"SubjectId\")['MisconceptionId'].nunique().sort_values(ascending = False).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
